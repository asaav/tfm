\section*{Resumen}
\addcontentsline{toc}{section}{Resumen}
\markright{Resumen}

En este trabajo de fin de máster se ha abordado el análisis, diseño e implementación de un proyecto de visión por computador utilizando \textit{deep learning} desde cero, creando un dataset propio a partir de vídeos obtenidos en un entorno real. El objetivo principal era crear un dataset utilizando vídeos de partidos de volleyball. Como objetivo adicional y utilizando el dataset mencionado, también queríamos obtener el mejor modelo posible capaz de detectar el balón en todos los frames vídeos de partidos reales, y hacer su seguimiento sin utilizar ningún sistema de coherencia temporal. Esto es útil de cara a análisis deportivo o \textit{scouting}, dando la posibilidad de analizar trayectorias, golpeos y velocidades del balón.

Las herramientas que se han utilizado en el proyecto son Python como lenguaje de desarrollo, y las librerías OpenCV y Tensorflow, las cuales nos permiten aplicar de visión por computador y entrenar modelos de redes neuronales, respectivamente. La segunda librería es especialmente importante para nuestro cometido ya que es la que nos va a dar todo el conjunto de herramientas para obtener un modelo \textit{deep learning} que cumpla la tarea que hemos planteado.

Las imágenes se obtendrán de una cámara modelo AXIS P1365-E Mk II, instalada en el pabellón Eduardo Linares de Molina de Segura, donde entrena el club de volleyball femenino Molina Volley, que se ha prestado a proporcionarnos imágenes de partidos. La cámara nos dará imágenes en vista cenital del campo en vídeos de 1080p y 30FPS.

Los objetivos del proyecto son, pues, la obtención de un dataset utilizando vídeos en crudo de la mencionada cámara, los cuales procesaremos para obtener imágenes de ejemplo con la presencia de balón y sin ella, y utilizaremos estas imágenes para alimentar un modelo de red neuronal completamente convolucional (FCN), cuyas ventajas sobre un modelo convolucional convencional son principalmente que acepta imágenes de cualquier tamaño, lo cual significa que podremos utilizar el modelo una vez entrenado para predecir frames de los vídeos reales. Un problema a considerar en este aspecto del proyecto es la dificultad de obtener ejemplos de forma automática de los vídeos, ya que, aunque se utilizará mi TFG que actúa como antecesor de este trabajo, este proyecto tenía problemas en los solapamientos entre jugadoras y balón. Para sortear este problema, no queda otra opción que completar el resto del dataset con imágenes tomadas de forma manual y depurar finalmente los datos.

Otra técnica a aplicar de cara al entrenamiento del modelo será la de Data Augmentation, que permitirá una mayor regularización del modelo, aplicando transformaciones aleatorias a las imágenes de entrenamiento del dataset. Estas modificaciones deberían ayudar a que el modelo extraiga las \textit{features} más relevantes de cada imagen.

La arquitectura elegida fue finalmente, como se ha dicho, una red neuronal FCN, que tiene la ventaja de procesar imágenes de cualquier tamaño. Durante el entrenamiento, se obtuvo una precisión de hasta 99\% sobre el conjunto de test tras hacer una selección de hiperparámetros, aunque se apreciaba un problema de falsos negativos una vez aplicado el detector a frames completos. Para solucionar este problema, se aplicó una técnica llamada Hard Negative Mining. Esta técnica consiste en utilizar los errores del modelo en entornos reales, los partidos en nuestro caso, e introducirlos como ejemplos en el dataset con el que hemos entrenado dicho modelo. El resultado deseado es que el modelo aprenda de sus errores y vaya depurándolos como parte del proceso de aprendizaje, mejorando su salida.

Utilizando la técnica de Hard Negative Mining se logró un modelo suficientemente bueno como para poder hacer seguimiento del balón, si bien este seguimiento no es perfecto debido a las dificultades intrínsecas de algunos frames, algunas veces causadas por la forma borrosa del balón, otras veces causadas por la similitud entre el balón y otros objetos de la escena en color o forma. Para salvar este tipo de errores no queda otra opción que la de implementar alguna forma por rudimentaria que sea de coherencia temporal ya que ha visto que la detección desde cero en todos los frames no es posible en estas circunstancias.

En conclusión, el proyecto ha llegado a una conclusión satisfactoria pese a los obstáculos con los que nos hemos ido encontrando durante el camino, durante todas las fases de este. La mejor solución de cara a una mejora futura sería utilizar un sistema de etiquetado distinto que el actual, que es la asignación de una clase a la imagen en global, y en su lugar, etiquetar cada píxel de esta. Este cambio de paradigma haría de este problema uno de segmentación visual, y dado que una FCN es la arquitectura idónea para este tipo de problemas, no sería necesaria una gran modificación. Sin embargo, hay que tener en cuenta que el etiquetado de tal cantidad de datos es una tarea de una envergadura tal que quedaría fuera del alcance del trabajo actual.


\newpage

\begin{otherlanguage}{english}
    
\section*{Extended Abstract}
\addcontentsline{toc}{section}{Extended Abstract}
\markright{Extended Abstract}

In this end of masters’ project, we covered the analysis, design and implementation of a deep learning-based computer vision solution from scratch, building our own dataset using real images from a camera. This camera, which is installed in the Eduardo Linares high school’s sports hall, has a top-down view of a volleyball court. The videos from the camera are 1920x1080 resolution with 30 frames per second.
Therefore, our main purpose was to make this dataset and, as a side objective, to train a neural network model using it that was capable of detecting a ball in a volleyball match in every frame of the videos that we will use, without any form of temporal coherence mechanism. This model would be useful for sport analysis and scouting purposes while being very cheap to put in motion.

Computer vision is a field of knowledge that seeks to make computers able to understand images and videos at a human level. Although it works with computers, it is not just a matter of research for computer scientists: there are psychologists, opticians and several other scientific researchers actively searching for new algorithms and techniques to make computer vision as close to that of humans as possible. In its beginnings, the difficulty of computer vision was often underestimated, but nowadays it is considered as one of the main barriers in the way to a true AI. Proof of that underestimation is that in 1966, an MIT student was assigned a summer project which consisted in attaching a camera to a computer and making it describe in natural language what it saw on that camera. Later, the world of computer research began to realize the true difficulty inherent to the issue at hand.

Over the years, a lot of algorithms, techniques and models have been developed, from simple contours and border detections to visual segmentation of a scene in real time. The most important advancement so far in this discipline has been the development of ANNs (Artificial Neural Networks), which have proven to be very successful in a different array of domains. This approach to computer vision has been the dominant trend from the 2000s until today because of the surge of Internet and the large, labelled datasets that have come with it along with the improvement of computation capabilities of modern computers.

Neural networks are not a new concept, in fact, they were proposed back in 1943 by Warren McCulloch and Walter Pitts in an article. ANNs have gone through two research booms until today, that we see the third and maybe final wave of progress in this kind of models.

Currently, there are plenty of computer vision solutions to a wide range of problems. In sports, for example, we can find Hawk-Eye, a popular computer vision system used mainly in tennis buy also in some other sports. In tennis, Hawk-Eye is used by referees and players to help determine if a ball was out of bounds or not. There are also solutions oriented to gather statistics useful for scouting purposes and coaching, like SportsVU, which uses images from multiple cameras to present statistics such as heat maps, possession maps, passing maps, etc. This system can be used in several sports, like basketball, football, rugby and some others. Lastly, we have solutions oriented to the audience, Intel 360 Replay is one of those. Again, this technology processes data from many cameras around the playing field (38 in the case of football) to provide 3D reconstructed replays of actions of the game.

Using deep learning there have also been several solutions, such as DeepBall, which was an object detector specialized for ball detection in long shot videos, using a fully convolutional network (FCN) and trained with the ISSIA-CNR Soccer dataset. The method achieved an 87,7\% accuracy using data augmentation. The shortcomings were ball occlusions and small objects very similar to the ball such as players’ boots, goalkeepers’ gloves or some bits of the billboards.

About the goals of this project, the main purpose was, as has been discussed, to build a dataset from images with a top down perspective to a volleyball court from a camera installed in the Eduardo Linares high schools’ sports hall. As a second objective, we sought to train a neural network capable of determining the presence of the ball in an image with enough accuracy to be able to track the ball in the video. The neural network will be an FCN because it has the advantage that it can process images of any given size, although our training images will be 56x56.
The tools we have used to develop this project are: 

\begin{itemize}
    \item Python. Being one of the most used programming languages for machine learning and scientific data processing, as well as a very easy language to develop in, Python is a sure choice when dealing with deep learning project such as this one. Python also has lots of libraries that will help us in our task, like TensorFlow or OpenCV, among others.
    \item TensorFlow. This is maybe the most important tool in this project. TensorFlow, alongside with Keras, provided us with the API to design and train several neural network architectures.
    \item OpenCV. This was a very useful library, that helped us in the computer vision related tasks as well as in acquiring some of the examples in our dataset.
    \item Git. One of the most important aspects in software development of any kind is version control software, such as Git which is the most popular VCS now because of its simplicity and power. Using it was useful for feedback purposes from the tutors as well as keeping a historic changelog.
\end{itemize}

Before creating our dataset, we checked if a generalist approach would be enough to solve the problem in hand. For this purpose, we used a model implemented in OpenCV, which is GOTURN, short for Generic Object Tracking Using Regression Networks. This method uses an underlying neural network which is trained using a ALOV300++ dataset, which is a publicly available dataset containing images for several categories of object such as people or balls. To put this model in motion, we just needed to download the trained weights from Internet and use them in our software. The results of this model were not very good, since the tracking of our ball failed within the first seconds of initialising it and attached commonly to a line of the court. Because of this, we concluded that the generalist approach was not enough for this problem, and we would need a solution more adjusted to our purpose.

As to the making of the dataset, it was conformed of positive and negative examples. To get all the example images, there was an automatic and a manual part. As for the automatic part, my end-of-degree project was used, where a ball detector was developed using background subtraction. Nevertheless, we found the same limitations that were present in that project, that were mainly the overlapping between players and the ball, and some instances where players were identified as ball. Because of these limitations, the positive examples would be skewed towards instances where the ball is isolated and no player near it. To acquire negative examples, we just picked a random position from the frame that did not contain the ball.

Once done with this process, we have 9014 images, of which 6886 are negatives and 2128 are positives. As we discussed, the system has some problems in detection, so these images will need to be cleaned by hand. After manually cleaning the dataset, we are left with 8023 images, of which 6877 are negatives and 1146 are positives.

With a clean dataset, we needed to compensate for the shortcomings of the automatic approach which were mainly overlaps between players and ball. On the negative examples, we needed some examples of objects other than the background to help the model in the learning process. Since we were lacking this kind of examples, we handpicked some more examples from the videos, bringing the total count of examples to 9526 with 6961 negatives and 2565 positives. For the training part, the dataset was split in an 80-10-10\% proportion between training, validation and test, respectively. 

Although almost 10000 examples is an arguably high number, it still does not guarantee that the model is going to learn all the features it needs, so we used a technique called data augmentation. This consists in applying a random transformation to each image in the train dataset to amplify the number of images available to the model, helping regularize its results.

As said before, we picked an FCN architecture, for its versatility when it comes to processing images of any size, so once trained in the dataset, our model should be capable of predicting frames of the videos themselves. Using the default parameters, the model gave an accuracy over 97\%.

To begin to adjust the hyperparameters of our model, first we set up Early Stopping, which reduces training time by stopping it once the model does not improve in a given metric, in our case, validation loss and also prevents it from overfitting training data.

Since the model tended to fluctuate in the training metrics, we adjusted the learning rate from a 10-3 ¬ value to a 10-4 which makes the model learn slower but at a more stable pace, hopefully achieving a better solution.

The last parameter that was adjuster was class weight. This parameter was important because of the class imbalance that our dataset has, in order to avoid the model to become very skewed toward the negatives. We raised the class weight for the positive examples to 2.5, a value that would put a similar importance between positive and negative classes, and it showed an accuracy in the test dataset of 99.47\%.

Even though our model was able to identify much better the ball in scenes, there was a good deal of false positives that needed to be addressed when testing the model against the videos. In order to clean those false positives up, we used those very errors as training examples in an iterative process, called Hard Negative Mining.

As said, Hard Negative Mining consists in taking real environment errors in a model and introducing them in the dataset that was used to train said model. This process can be performed over negative and positive examples and can be done any number of times until we are left with a model that satisfies our requirements.

Nevertheless, determining what an error is requires some form of labelling in every frame of the videos in order to know which positives are real and which ones are errors of the model. Labelling every frame in over 20 minutes of videos that we have at the moment would be a very demanding task to perform and is out of the scope of this project. Instead, we took a small sample of 30 images and labelled the position of the ball in each one. With that labels in place, we made automated the process of determining errors and creating the new dataset combining the original dataset with the new examples.

To calculate every error, we needed to make sure that the examples were not very close to each other in order to avoid examples that look exactly the same ending up in different subsets of the dataset. This means we must check the position of every patch not just in one of the frames, but in every one of them. Once calculated every error, we select them taking no more than half of the number of images in the dataset and split them in the same 80-10-10\% proportion. The new images are then introduced in the dataset and we delete the same number of images from it that we will introduce.

One aspect to consider in this process is the amount of memory that it would require in a big enough dataset and with a rather big number of iterations. To avoid that, instead of copying the full dataset in every iteration, we use symbolic links to the images of the last iteration and just save as new files the errors that we have detected.

Usually no more than 3 iterations of this process are necessary to achieve a model that is good enough. The false negatives are for the most part solved, but we still must manage a little amount that occur due to intrinsic difficulty of some frames.

To initialize our tracker, we will first give it a ROI in order to have a human-supervised first position of the ball and then we will keep following that ROI as the ball moves instead of running the model over the full image, which will help us have a better performance.

% performance paragraph

In summary, we ended with a model that was good at performing the task in hand but not very consistent and very prone to some errors that cannot be easily avoided like instances when the ball is too blurry to recognize and in small objects like players’ shoes.

As future improvements, there are a lot of tasks that would improve this project but cannot have been performed due to their size or time requirements that made them out of scope. Some of these tasks are:

\begin{itemize}
    \item Use of any kind of temporal coherence algorithm like Hidden Markov Models, Kalman filters or RNNs.
    \item Label the position of the ball in every frame of the videos, thus having a semantic segmentation approach and use a model that instead of predicting the full image, gives a prediction for each pixel of it.
    \item In pair with the former, some popular and established FCN architecture may be used, such as YOLO or R-CNN.
\end{itemize}

As a final improvement and something that is out of reach is the improvement of both the resolution and framerate of the camera, which would help reduce some of the intrinsic errors that we mentioned.

\end{otherlanguage}
\newpage